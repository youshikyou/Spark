Spark Session provides a single point of entry to interact with Spark DataFrames
Spark Session is used to create DataFrame,register DataFrames,execute SQL queries 
Spark Session is available in PySpark shell as spark





df.show()
df.columns()
df.count()
df.grouby()
df.select()
df.dropDuplicates()
df.filter(df.col == "xxx")
df.toPandas(), pandas is in-memory and single server based structures.
spark.read.csv(file_path, header=True, inferSchema=True)
df.printSchema()
df.describe().show()
df.createOrReplaceTempView()
